{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scigeek72/GNN_Repo/blob/main/Predicting_Drug_Drug_Interactions_using_Graph_Neural%C2%A0Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9eWJ1Lwid-g"
      },
      "source": [
        "# Predicting Drug-Drug Interactions using Graph Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "By Ananth Agarwal, Meg Richey, and Zeb Mehring as part of the Stanford CS 224W Fall 2021 course project.\n",
        "\n",
        "N.B. Follow along with the companion [Medium article](https://medium.com/stanford-cs224w/predicting-drug-drug-interactions-using-graph-neural-networks-6a093cc59a33)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxSoQEiHYM5"
      },
      "source": [
        "Taking certain combinations of prescription drugs can be unsafe if the drugs interact with each other. Medical professionals and patients rely on drug-drug interaction databases to make safe medical decisions. In this Colab, we will learn about Graph Neural Networks and how we can train a model to predict whether two drugs will interact with each other.\n",
        "\n",
        "Outline:\n",
        "* Loading the drug-drug interaction graph from Open Graph Benchmark (OGB)\n",
        "* Defining our first Graph Neural Network (GNN) model: GraphSAGE\n",
        "* Exploring defining a modification to the traditional GraphSAGE operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBgLAYC9HxC0"
      },
      "source": [
        "# Device\n",
        "We recommend using a GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3P19x77ILAz"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEGCHVJtikSo",
        "outputId": "fa27ebc4-843f-4cb2-a49f-4ff99fa38b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 575 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 521 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581969 sha256=6dc6a1c439fa16312c3c0717f8b06f72c7eb2212c3dc152d53c5b9621adc9f18\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.1.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.62.3)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=abdd2c76a99a781169c3b5a5b97f6bd4fc9ce0fbeef5828c90ef13fc64aa6c36\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.2 outdated-0.2.1\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUHc02YsiiUv"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oEjyChoKWfv"
      },
      "source": [
        "Setup using GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrX9HTzZWx3M"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8njTGGCWjvWN"
      },
      "source": [
        "# OGB Drug-Drug Interaction Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpO_ieaRXNki"
      },
      "source": [
        "We will be using the [PyTorch Geometric library (PyG)](https://github.com/pyg-team/pytorch_geometric) throughout this Colab. PyTorch Geometric is built on top of PyTorch to simplify implementation of Graph Neural Networks, which we will cover in-depth. \n",
        "The drug-drug interaction (DDI) dataset **ogbl-ddi** is provided by **[Open Graph Benchmark (OGB)](https://ogb.stanford.edu/)**, which provides datasets for a variety of Graph ML tasks. ogbl-ddi is a link prediction dataset [1].\n",
        "\n",
        "Following the example from the [OGB website](https://ogb.stanford.edu/docs/linkprop/#pyg), we can load the DDI dataset into PyG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUDQoZUdixSD",
        "outputId": "1d635f6b-469a-4f02-d45f-da1d62363cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/linkproppred/ddi.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.04 GB: 100%|██████████| 46/46 [00:48<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/ddi.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 31.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1665.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n",
            "The ogbl-ddi dataset has 1 graph(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from ogb.linkproppred import PygLinkPropPredDataset\n",
        "\n",
        "dataset_name = 'ogbl-ddi'\n",
        "dataset = PygLinkPropPredDataset(name=dataset_name)\n",
        "print(f'The {dataset_name} dataset has {len(dataset)} graph(s).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBCDGvV-E4w"
      },
      "source": [
        "The dataset contains 1 graph, the full DDI network. Define the DDI graph as $G = (V, E)$, where $V$ is the set of nodes and $E$ is the set of edges.\n",
        "Following the [OGB definitions](https://ogb.stanford.edu/docs/linkprop/#ogbl-ddi):\n",
        "* Each **node** $v \\in V$ is an FDA-approved or experimental drug\n",
        "* An **edge** between two drugs $u$ and $v$ indicates that taking the two drugs together has a considerably different effect than the expected effect if they acted independently\n",
        "\n",
        "Let's get the graph, which is a [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs) object, from `dataset` and print some of its attributes to learn more about the graph's structure. Note that PyG gives us a graph that only contains training edges, so in reality the full graph contains more edges. More on the dataset split later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1TuCUbS_XZi",
        "outputId": "07891997-8525-4315-984f-76b5f619a2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DDI graph object: Data(edge_index=[2, 2135822])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/data/storage.py:264: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  \" to suppress this warning\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes |V|: 4267\n",
            "Number of (training) edges |E|: 2135822\n",
            "Is undirected: True\n",
            "Average node degree: 500.54\n",
            "Number of node features: 0\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n"
          ]
        }
      ],
      "source": [
        "# This graph only contains training edges\n",
        "ddi_graph = dataset[0]\n",
        "\n",
        "print(f'DDI graph object: {ddi_graph}')\n",
        "print(f'Number of nodes |V|: {ddi_graph.num_nodes}')\n",
        "print(f'Number of (training) edges |E|: {ddi_graph.num_edges}')\n",
        "print(f'Is undirected: {ddi_graph.is_undirected()}')\n",
        "# Note that since the graph is undirected, PyG includes both (u, v) and (v, u) as edges\n",
        "print(f'Average node degree: {ddi_graph.num_edges / ddi_graph.num_nodes:.2f}')\n",
        "print(f'Number of node features: {ddi_graph.num_node_features}')\n",
        "print(f'Has isolated nodes: {ddi_graph.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {ddi_graph.has_self_loops()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWMI5rZGbP50"
      },
      "source": [
        "`edge_index` is an important property that we will need for building GNNs. It is a list of edges with shape `[2, |E|]`. Important: since `ddi_graph` is undirected, $E$ includes both $(u, v)$ and $(v, u)$ for two drugs $u$ and $v$ that interact.\n",
        "\n",
        "Note that there are no node features, so we will need to address this when building our model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tm_05FFc9cS"
      },
      "source": [
        "# Task\n",
        "\n",
        "The DDI graph is not static; it will evolve over time, for example new drugs will be discovered. We want to develop a model where we can input two drugs and output a prediction of if they interact with each other. This is a **link prediction** task: given two nodes $u, v \\in V$, predict the existence of edge $(u, v)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s9gO950_4Vc"
      },
      "source": [
        "# Dataset Split\n",
        "\n",
        "We need to have separate **train**, **validation**, and **test** datasets. Generally, setting up data splits for link prediction is tricky, because we only have our one graph of known interactions to work with. Fortunately, OGB provides us a dataset split.\n",
        "\n",
        "First, some definitions:\n",
        "* **Positive edges** are edges that exist in the graph: the set $\\{(u, v) \\in E\\}$, where $u, v \\in V$.\n",
        "* **Negative edges** are edges that don't exist in the graph: the set $\\{(u, v) \\notin E\\}$. \n",
        "We need positive and negative edges to train our link prediction model.\n",
        "\n",
        "The code below gets the edge split. [As explained on the OGB website](https://ogb.stanford.edu/docs/linkprop/#ogbl-ddi), it is a \"protein-target split\": the edges are split such that drugs in the validation and test sets target different proteins than the drugs in the training set. The GNN will be trained using only the edges in the training set - at training time, it doesn't know anything about the validation or test edges. You can think of this as essentially removing the validation and test edges from the full known DDI graph when we are training the model on it. PyG has facilitated this for us: as noted before, `ddi_graph` only contains training edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBPnvTugW1gF"
      },
      "outputs": [],
      "source": [
        "split_edges = dataset.get_edge_split()\n",
        "train_edges, valid_edges, test_edges = split_edges['train'], split_edges['valid'], split_edges['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyLw0A4WXLfm"
      },
      "source": [
        "Below we check how many edges are in each set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1VP7Io9ZI9q",
        "outputId": "37bf357f-83e1-45dc-d93b-e8e31fad621d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training positive edges: 1067911\n",
            "Number of validation positive edges: 133489\n",
            "Number of validation negative edges: 101882\n",
            "Number of test positive edges: 133489\n",
            "Number of test negative edges: 101882\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of training positive edges: {train_edges[\"edge\"].shape[0]}')\n",
        "print(f'Number of validation positive edges: {valid_edges[\"edge\"].shape[0]}')\n",
        "print(f'Number of validation negative edges: {valid_edges[\"edge_neg\"].shape[0]}')\n",
        "print(f'Number of test positive edges: {test_edges[\"edge\"].shape[0]}')\n",
        "print(f'Number of test negative edges: {valid_edges[\"edge_neg\"].shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7W9ReYPpCn"
      },
      "source": [
        "Quick clarification note: `ddi_graph.edge_index` has shape [2, 2 * `train_edge[\"edge\"].shape[0]`] because we use the `edge_index` in our GNN, which requires sending information from $u$ to $v$ and $v$ to $u$ (as we will see below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHtYOJ6Z16K"
      },
      "source": [
        "Note that validation and test negative edges are given to us by PyG, but training negative edges are not. As we will see, while training we don't just work with one set of negative edges; instead, we sample negative edges from the graph for each training mini-batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy4lguEXXy1m"
      },
      "source": [
        "# Models\n",
        "\n",
        "Our overall model has two parts: \n",
        "\n",
        "1) Graph Neural Network to generate node embeddings\n",
        "\n",
        "2) Deep neural network that outputs a probability for a link prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwrWOr_7bHMy"
      },
      "source": [
        "## Graph Neural Networks (GNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lWm3BxOGFT_"
      },
      "source": [
        "**Graph Neural Networks** are designed to take advantage of relational structure in networks to develop high-quality predictions. The input is the network of interest, and the output is node embeddings that can be applied to node-level, edge-level, and graph-level tasks. GNN layers have two primary components:\n",
        "* **Message passing** between nodes and their neighbors\n",
        "* **Aggregation** of received messages for each node to update the node's embedding\n",
        "\n",
        "Let $h_v^{(l)}$ be the **node embedding** vector of node $v$ at layer $l$ of the GNN. The embedding at the next layer $h_v^{(l + 1)}$ is determined by the messages received from neighbors, the aggregation function applied to these messages, and how this result is combined with $h_v^{(l)}$. We can formally express this using the following equation: \n",
        "$$h_v^{(l + 1)} = \\text{UPDATE}(h_v^{(l)}, \\text{AGG}(\\{m_u^{(l + 1)}, \\forall u \\in N(v)\\}))$$\n",
        "$$\\text{Equation (1)}$$\n",
        "where $N(v)$ is the set of neighbors of $v$, $m_u^{(l + 1)}$ is the message passed by neighbor $u$ in layer $l + 1$, AGG is the aggregation function applied to messages, and UPDATE is the update function to compute the updated embedding. Different GNN layer architectures use different message, aggregation, and update functions. We will use the **GraphSAGE** framework here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK2RvzrManrJ"
      },
      "source": [
        "### GraphSAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53XtxCEUFPLw"
      },
      "source": [
        "GraphSAGE ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) is a GNN that uses the following operator to learn node embeddings [2]:\n",
        "$$h_v^{(l + 1)} = W_1 \\cdot h_v^{(l)} + W_2 \\cdot \\text{mean}(\\{h_u^{(l)}, \\forall u \\in N(v)\\})$$\n",
        "$$\\text{Equation (2)}$$\n",
        "where $W_1$ and $W_2$ are learnable weight matrices. We can stack multiple layers that use this operator to build our GNN. PyG provides an implementation of this operator in the [`SAGEConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) class. For illustrative purposes, we will walk through the definition of the full GraphSAGE GNN module. We will use `SAGEConv` as the convolutional operator, but we will pass this as a parameter to creating our model, because later we will define a custom operator that we would like to experiment with instead.\n",
        "\n",
        "For now, we will not have any edge attributes (`edge_attr=None`), so you can ignore the `forward_with_edge_attr` function. We will revisit this later in the Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvUR_ZqK6JXc"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    \"\"\"Graph Neural Network built with the GraphSAGE architecture.\"\"\"\n",
        "\n",
        "    def __init__(self, conv, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        \n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        assert (num_layers >= 2), 'Have at least 2 layers'\n",
        "        # Add a conv for every layer. As with other neural networks, dimensions must match \n",
        "        # from one layer to the next.\n",
        "        # We also apply normalization, such that the embeddings that are output after\n",
        "        # each convolution layer are L2 normalized.\n",
        "        self.convs.append(conv(in_channels, hidden_channels, normalize=True))\n",
        "        for l in range(num_layers - 2):\n",
        "            self.convs.append(conv(hidden_channels, hidden_channels, normalize=True))\n",
        "        self.convs.append(conv(hidden_channels, out_channels, normalize=True))\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        if edge_attr is not None:\n",
        "            return self.forward_with_edge_attr(x, edge_index, edge_attr)\n",
        "\n",
        "        # x is the matrix of initial node embeddings, shape [N, in_channels]\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Conducts message passing and aggregation for layer i\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            # x now has shape [N, hidden_channels]\n",
        "            # Pass through non-linearity\n",
        "            x = F.relu(x)\n",
        "\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Generate final embeddings. x has shape [N, out_channels]\n",
        "        x = self.convs[self.num_layers - 1](x, edge_index)\n",
        "        return x\n",
        "  \n",
        "    def forward_with_edge_attr(self, x, edge_index, edge_attr):\n",
        "        # x is the matrix of initial node embeddings, shape [N, in_channels]\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Conducts message passing and aggregation for layer i\n",
        "            x = self.convs[i](x, edge_index, edge_attr)\n",
        "            # x has shape [N, hidden_channels]\n",
        "            # Pass through non-linearity\n",
        "            x = F.relu(x)\n",
        "\n",
        "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "        # Generate final embeddings. x has shape [N, out_channels]\n",
        "        x = self.convs[self.num_layers - 1](x, edge_index, edge_attr)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIyQ3Pxs-6tJ"
      },
      "source": [
        "Our GraphSAGE model with $K$ layers has the following parameters:\n",
        "* `in_channels`: Dimension of initial node embeddings: $h^{(0)}_v \\in \\mathbb{R}^{(in\\_channels)}, \\forall v \\in V$. Since the drugs have no node features, we will randomly initialize these vectors.\n",
        "* `hidden_channels`: Dimension of intermediary node embeddings: $h^{(1)}_v \\ldots h^{(K - 1)}_v \\in \\mathbb{R}^{(hidden\\_channels)}, \\forall v \\in V$\n",
        "* `out_channels`: Dimension of final node embeddings: $h^{(K)}_v \\in \\mathbb{R}^{(out\\_channels)}, \\forall v \\in V$\n",
        "* `num_layers`: Number of layers in our GNN, $K$. This is the number of times the GraphSAGE operator is applied.\n",
        "* `dropout`: Dropout is applied to the weight matrices $W_1$ and $W_2$\n",
        "\n",
        "In the OGB leaderboard for best performance on ogbl-ddi, Hu et al. (2020) ([paper](https://arxiv.org/abs/2005.00687), [code](https://github.com/snap-stanford/ogb/tree/master/examples/linkproppred/ddi)) demonstrated that GraphSAGE performs well [3].\n",
        "For tutorial simplicity, we default initialize these parameters to the same values used in their work, though we have made the parameters configurable so feel free to use the UI on the right to explore other values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxrwkmOPX65t"
      },
      "outputs": [],
      "source": [
        "#@title GraphSAGE parameters\n",
        "graphsage_in_channels = 256 #@param {type: 'number'}\n",
        "graphsage_hidden_channels = 256 #@param {type: 'number'}\n",
        "graphsage_out_channels = 256 #@param {type: 'number'}\n",
        "graphsage_num_layers = 2 #@param {type: 'number'}\n",
        "dropout = 0.5 #@param {type: 'slider', min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48lYoO9GKLOU"
      },
      "source": [
        "Since the drugs don't have any features, we create our own initial embeddings using `torch.nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IAZqW0UKkWX",
        "outputId": "da3bf52a-ece0-4337-e206-cb4349dc0a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/data/storage.py:264: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  \" to suppress this warning\")\n"
          ]
        }
      ],
      "source": [
        "initial_node_embeddings = torch.nn.Embedding(ddi_graph.num_nodes, graphsage_in_channels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xehDwiCG84g"
      },
      "source": [
        "`initial_node_embeddings` has shape [$|V|$, `graphsage_in_channels`]. Each row is the embedding of a node $v$.\n",
        "\n",
        "We initialize our GraphSAGE model next:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWAF_cTRG7fG"
      },
      "outputs": [],
      "source": [
        "graphsage_model = GraphSAGE(SAGEConv, graphsage_in_channels, \n",
        "                                 graphsage_hidden_channels,\n",
        "                                 graphsage_out_channels,\n",
        "                                 graphsage_num_layers, \n",
        "                                 dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXmHxjq8HwHN"
      },
      "source": [
        "The `forward` pass takes `initial_node_embeddings` as input, and passes it through `num_layers` `SAGEConv` layers to produce the final node embeddings. These final embeddings are a tensor with shape [$|V|$, `graphsage_out_channels`]. So far though, we only have embeddings for individual nodes. For link prediction, we need a model that takes two node embeddings as inputs, and outputs a prediction for the existence of an edge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mv2fv2eaqcT"
      },
      "source": [
        "## Deep Neural Network Link Predictor\n",
        "\n",
        "We combine the node embeddings for the edge we would like to predict by taking an element-wise product: $h_u^{K} \\circ h_v^{K}$. We now pass this through a 2-layer neural network that outputs a link prediction probability using a sigmoid function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txV7TZhCdzRw"
      },
      "outputs": [],
      "source": [
        "link_predictor_in_channels = graphsage_out_channels\n",
        "link_predictor_hidden_channels = link_predictor_in_channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvbJ0hKNbT0b"
      },
      "outputs": [],
      "source": [
        "class LinkPredictor(torch.nn.Module):\n",
        "    \"\"\"Generic deep neural network that transforms two inputs into a single output.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, dropout, out_channels=1,\n",
        "                concat=lambda x, y: x * y):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(nn.Linear(in_channels, hidden_channels), nn.ReLU(), \n",
        "                                  nn.Dropout(p=dropout), nn.Linear(hidden_channels, out_channels), nn.Sigmoid())\n",
        "        \n",
        "        self.concat = concat\n",
        "    \n",
        "    def forward(self, u, v):\n",
        "        x = self.concat(u, v)\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2P-Xozidr4A"
      },
      "outputs": [],
      "source": [
        "link_predictor = LinkPredictor(in_channels=link_predictor_in_channels, \n",
        "                               hidden_channels=link_predictor_hidden_channels, \n",
        "                               dropout=dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLKVLQHVauDm"
      },
      "source": [
        "# Training\n",
        "\n",
        "Training our full model (GraphSAGE + link predictor neural network) follows these steps:\n",
        "\n",
        "* For each `batch_size` mini-batch of training edges sampled using `torch_geometric.loader.DataLoader`:\n",
        "  * Run the GraphSAGE GNN forward pass starting with the initial node embeddings and the `edge_index` to generate node embeddings. Note that `edge_index` only contains training edges.\n",
        "  * Sample `batch_size` negative edges. PyG provides a utility function that does this.\n",
        "  * For each positive and negative edge, get the pair of node embeddings and run the forward pass of the link predictor to generate predictions\n",
        "  * Calculate loss for the predictions\n",
        "  * Backpropagate and update parameters\n",
        "\n",
        "Since we are predicting existence of edges (0 or 1), our loss function is **binary cross-entropy loss**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKh1KwifJsYp"
      },
      "outputs": [],
      "source": [
        "def train(graphsage_model, link_predictor, initial_node_embeddings, edge_index, \n",
        "          pos_train_edges, optimizer, batch_size, edge_attr=None):\n",
        "    \"\"\"Train the full model (GraphSAGE + LinkPredictor) using training edges.\"\"\"\n",
        "    \n",
        "    total_loss, total_examples = 0, 0\n",
        "\n",
        "    # Set our models to train\n",
        "    graphsage_model.train()\n",
        "    link_predictor.train()\n",
        "\n",
        "    # Iterate over batches of training edges (\"positive edges\")\n",
        "    # pos_samples is a Tensor of edges with dimension [batch_size, 2]\n",
        "    # (the last iteration may have fewer edges than batch_size)\n",
        "    for pos_samples in DataLoader(pos_train_edges, batch_size, shuffle=True):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run GraphSAGE forward pass\n",
        "        node_embeddings = graphsage_model(initial_node_embeddings, edge_index, edge_attr)\n",
        "\n",
        "        # Sample batch_size negative edges\n",
        "        # neg_samples is a Tensor with dimension [2, batch_size]\n",
        "        neg_samples = negative_sampling(edge_index, \n",
        "                                        num_nodes=initial_node_embeddings.size(0),\n",
        "                                        num_neg_samples=len(pos_samples),\n",
        "                                        method='dense')\n",
        "        \n",
        "        # Run link predictor forward pass on positive edge embeddings\n",
        "        pos_preds = link_predictor(node_embeddings[pos_samples[:, 0]], \n",
        "                                    node_embeddings[pos_samples[:, 1]])\n",
        "        \n",
        "        # Run link predictor forward pass on negative edge embeddings\n",
        "        neg_preds = link_predictor(node_embeddings[neg_samples[0]], \n",
        "                                    node_embeddings[neg_samples[1]])\n",
        "\n",
        "        preds = torch.concat((pos_preds, neg_preds))\n",
        "        labels = torch.concat((torch.ones_like(pos_preds), \n",
        "                                torch.zeros_like(neg_preds)))\n",
        "\n",
        "        loss = F.binary_cross_entropy(preds, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        num_examples = len(pos_preds)\n",
        "        total_loss += loss.item() * num_examples\n",
        "        total_examples += num_examples\n",
        "    \n",
        "    return total_loss / total_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndAJ-dNvmSyD"
      },
      "source": [
        "As with the GraphSAGE parameters, by default we set the learning rate and batch size used by Hu et al. (2020) ([paper](https://arxiv.org/abs/2005.00687), [code](https://github.com/snap-stanford/ogb/tree/master/examples/linkproppred/ddi)). Larger batch size helps to train the model faster. Additionally, we only train for 50 epochs for quicker analysis. Feel free to adjust the parameters and play around. `eval_steps` is how often we evaluate our model against the validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g49fJVV1KAhT"
      },
      "outputs": [],
      "source": [
        "#@title Training Parameters\n",
        "lr = 0.005 #@param {type: 'number'}\n",
        "batch_size = 65536 #@param {type: 'number'}\n",
        "epochs = 50  #@param {type: 'number'}\n",
        "eval_steps = 5 #@param {type: 'number'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfHDjlU8Efxy"
      },
      "source": [
        "Create an Adam optimizer with our model parameters and the learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYiSCRYvEjqh"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(list(graphsage_model.parameters()) + list(initial_node_embeddings.parameters()) + list(link_predictor.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqhW6yUum5Yt"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFq8cCJynvdy"
      },
      "source": [
        "We evaluate our model on the validation and test positive and negative edges provided in the OGB dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufW7U1EApvAy"
      },
      "outputs": [],
      "source": [
        "pos_valid_edges = valid_edges['edge'].to(device)\n",
        "neg_valid_edges = valid_edges['edge_neg'].to(device)\n",
        "pos_test_edges = test_edges['edge'].to(device)\n",
        "neg_test_edges = test_edges['edge_neg'].to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg9HMMkeqiuC"
      },
      "source": [
        "The evaluation procedure is as follows:\n",
        "\n",
        "* Run the GraphSAGE GNN forward pass starting with the initial node embeddings and the `edge_index` to generate node embeddings. Note that `edge_index` only contains training edges.\n",
        "* For both the validation and test sets, for each positive and negative edge, run the forward pass of the link predictor to generate predictions.\n",
        "* Calculate **Hits@K** for the validation and test predictions.\n",
        "\n",
        "Hits@K is calculated by the `Evaluator` object that OGB provides to us for ogbl-ddi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBgkDu7HtQ2d"
      },
      "outputs": [],
      "source": [
        "from ogb.linkproppred import Evaluator\n",
        "\n",
        "evaluator = Evaluator(name = dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiHobKw8tTsY"
      },
      "source": [
        "Hits@K is equal to the ratio of positive edges that have a prediction value higher than the K-th highest value negative edge. So for example, if we are evaluating Hits@3 using the following values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP6WYrlltsfJ",
        "outputId": "3220dafa-4f38-49ed-e50d-f3ee4eb8a1ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hits@3': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "evaluator.K = 3\n",
        "evaluator.eval({'y_pred_pos': torch.tensor([0.95, 0.7, 0.6, 0.4]), 'y_pred_neg': torch.tensor([0.6, 0.5, 0.45, 0.2, 0.1])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq00XqB5twOZ"
      },
      "source": [
        "The output is 3/4 because the 3rd highest negative prediction is 0.45, and 3 out of the 4 positive edges had predictions higher than it.\n",
        "\n",
        "Following OGB's recommendation, we evaluate our DDI model using Hits@20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPMgucOqCR0j"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(graphsage_model, link_predictor, initial_node_embeddings, edge_index, pos_valid_edges, neg_valid_edges, pos_test_edges, neg_test_edges, batch_size, evaluator, edge_attr=None):\n",
        "    graphsage_model.eval()\n",
        "    link_predictor.eval()\n",
        "\n",
        "    # Run GraphSAGE forward pass\n",
        "    final_node_embeddings = graphsage_model(initial_node_embeddings, edge_index, edge_attr)\n",
        "\n",
        "    # Run link predictor forward pass on positive validation edge embeddings\n",
        "    pos_valid_preds = []\n",
        "    for pos_samples in DataLoader(pos_valid_edges, batch_size):\n",
        "        pos_preds = link_predictor(final_node_embeddings[pos_samples[:, 0]], \n",
        "                                    final_node_embeddings[pos_samples[:, 1]])\n",
        "        pos_valid_preds.append(pos_preds.squeeze())\n",
        "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
        "    \n",
        "    # Run link predictor forward pass on negative validation edge embeddings\n",
        "    neg_valid_preds = []\n",
        "    for neg_samples in DataLoader(neg_valid_edges, batch_size):\n",
        "        neg_preds = link_predictor(final_node_embeddings[neg_samples[:, 0]], \n",
        "                                    final_node_embeddings[neg_samples[:, 1]])\n",
        "        neg_valid_preds.append(neg_preds.squeeze())\n",
        "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
        "\n",
        "    # Run link predictor forward pass on positive test edge embeddings\n",
        "    pos_test_preds = []\n",
        "    for pos_samples in DataLoader(pos_test_edges, batch_size):\n",
        "        pos_preds = link_predictor(final_node_embeddings[pos_samples[:, 0]], \n",
        "                                    final_node_embeddings[pos_samples[:, 1]])\n",
        "        pos_test_preds.append(pos_preds.squeeze())\n",
        "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
        "    \n",
        "    # Run link predictor forward pass on negative test edge embeddings\n",
        "    neg_test_preds = []\n",
        "    for neg_samples in DataLoader(neg_test_edges, batch_size):\n",
        "        neg_preds = link_predictor(final_node_embeddings[neg_samples[:, 0]], \n",
        "                                    final_node_embeddings[neg_samples[:, 1]])\n",
        "        neg_test_preds.append(neg_preds.squeeze())\n",
        "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
        "\n",
        "    # Calculate Hits@20\n",
        "    evaluator.K = 20\n",
        "    valid_hits = evaluator.eval({'y_pred_pos': pos_valid_pred, 'y_pred_neg': neg_valid_pred})\n",
        "    test_hits = evaluator.eval({'y_pred_pos': pos_test_pred, 'y_pred_neg': neg_test_pred})\n",
        "\n",
        "    return valid_hits, test_hits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsis7IPsb7iv"
      },
      "source": [
        "We are ready to run the training and evaluation. The following cell takes about 12 minutes to run with the default parameters. At the end, a plot will be shown that shows how the training loss, validation Hits@20, and test Hits@20 progressed over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "o6_IAoMMQdRU",
        "outputId": "c37f83fb-f8ad-43fd-deb6-5b302cab1a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.3300:  10%|█         | 5/50 [01:13<11:13, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Validation Hits@20: 0.0587, Test Hits@20: 0.0762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2420:  20%|██        | 10/50 [02:27<10:00, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10, Validation Hits@20: 0.1595, Test Hits@20: 0.1104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1949:  30%|███       | 15/50 [03:41<08:45, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 15, Validation Hits@20: 0.2180, Test Hits@20: 0.1196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1670:  40%|████      | 20/50 [04:54<07:30, 15.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 20, Validation Hits@20: 0.3005, Test Hits@20: 0.1912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1465:  50%|█████     | 25/50 [06:08<06:16, 15.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 25, Validation Hits@20: 0.3854, Test Hits@20: 0.2424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1306:  60%|██████    | 30/50 [07:22<05:01, 15.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 30, Validation Hits@20: 0.4288, Test Hits@20: 0.2869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1216:  70%|███████   | 35/50 [08:36<03:45, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 35, Validation Hits@20: 0.4392, Test Hits@20: 0.3719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1151:  80%|████████  | 40/50 [09:50<02:30, 15.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 40, Validation Hits@20: 0.4802, Test Hits@20: 0.2897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1109:  90%|█████████ | 45/50 [11:04<01:15, 15.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 45, Validation Hits@20: 0.4808, Test Hits@20: 0.2418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1055: 100%|██████████| 50/50 [12:18<00:00, 14.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 50, Validation Hits@20: 0.5015, Test Hits@20: 0.3067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs_bar = trange(1, epochs + 1, desc='Loss n/a')\n",
        "\n",
        "edge_index = ddi_graph.edge_index.to(device)\n",
        "pos_train_edges = train_edges['edge'].to(device)\n",
        "\n",
        "losses = []\n",
        "valid_hits_list = []\n",
        "test_hits_list = []\n",
        "for epoch in epochs_bar:\n",
        "    loss = train(graphsage_model, link_predictor, initial_node_embeddings.weight, edge_index, pos_train_edges, optimizer, batch_size)\n",
        "    losses.append(loss)\n",
        "\n",
        "    epochs_bar.set_description(f'Loss {loss:0.4f}')\n",
        "\n",
        "    if epoch % eval_steps == 0:\n",
        "        valid_hits, test_hits = test(graphsage_model, link_predictor, initial_node_embeddings.weight, edge_index, pos_valid_edges, neg_valid_edges, pos_test_edges, neg_test_edges, batch_size, evaluator)\n",
        "        print()\n",
        "        print(f'Epoch: {epoch}, Validation Hits@20: {valid_hits[\"hits@20\"]:0.4f}, Test Hits@20: {test_hits[\"hits@20\"]:0.4f}')\n",
        "        valid_hits_list.append(valid_hits['hits@20'])\n",
        "        test_hits_list.append(test_hits['hits@20'])\n",
        "    else:\n",
        "        valid_hits_list.append(valid_hits_list[-1] if valid_hits_list else 0)\n",
        "        test_hits_list.append(test_hits_list[-1] if test_hits_list else 0)\n",
        "\n",
        "plt.title(dataset.name + \": GraphSAGE\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.plot(losses, label=\"Training loss\")\n",
        "plt.plot(valid_hits_list, label=\"Validation Hits@20\")\n",
        "plt.plot(test_hits_list, label=\"Test Hits@20\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1pnOCDZkhT9"
      },
      "source": [
        "Our model performed well! \n",
        "There is some randomness in initial embeddings and the data loader. In our run, our final Validation Hits@20 is 0.50, and Test Hits@20 is 0.40. Further improvements that could be made include:\n",
        "* Training for longer (we set a small number of epochs by default to reduce the time spent waiting for results)\n",
        "* Exploring gradient clipping, weight initialization distributions, and whether normalization of node embeddings helps in the `SAGEConv` layer. Some of these are explored in Hu et al. (2020) ([paper](https://arxiv.org/abs/2005.00687), [code](https://github.com/snap-stanford/ogb/tree/master/examples/linkproppred/ddi)) to obtain strong results.\n",
        "\n",
        "We will move on though to showing how we can modify the GraphSAGE operator to include other graph attributes that gives our model more information to learn from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUab_S1jBl7j"
      },
      "source": [
        "# Defining A Custom GraphSAGE Operator\n",
        "\n",
        "The DDI graph given to us didn't have any node or edge features, but we can augment the data we input into the model by calculating our own metrics. The paper that is currently at the top of the OGB DDI leaderboard by Yang and Lu (2021) ([paper](https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf), [code](https://github.com/lustoo/OGB_link_prediction)) makes a modification to the standard GraphSAGE operator from Equation (2) [4]. They define an **edge attribute** (a value associated with every edge) that for every edge, calculates the average distance between the two nodes and a set of **anchor nodes** sampled from the graph. We will implement a scaled-down version of the author's approach here (due to Colab GPU's default memory and runtime restrictions) to demonstrate how it is possible to define your own graph convolutional layers in PyG.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjWi6qaptmpQ"
      },
      "source": [
        "For every edge $(u, v)$, we calculate the average distance to the set of anchor nodes. Let the set of anchor nodes be $V_A \\in V$. We can define this distance as follows:\n",
        "$$\\text{anchor_d}_{u, v} = \\frac{1}{|V_A|}\\sum_{v_a \\in V_A} d_{u, v_a} + d_{v, v_a}$$\n",
        "where $d_{u, v}$ is the shortest path between $u$ and $v$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YzJkPOGuxkl"
      },
      "source": [
        "The [NetworkX library](https://networkx.org/documentation/stable/index.html) defines functions that calculate shortest paths in networks. We use the PyG utility function to convert `ddi_graph` to a NetworkX undirected graph. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcfM0KfzNJt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123d6e7b-7204-4220-81b4-6c078aa4395d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/data/storage.py:264: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  \" to suppress this warning\")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "nx_ddi_graph = to_networkx(ddi_graph, to_undirected=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQWyl18cxQEB"
      },
      "source": [
        "We start with a default of 200 anchor nodes that we will sample from `nx_ddi_graph`, but we also make this configurable, so feel free to try other values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD3fqRm8xLVf"
      },
      "outputs": [],
      "source": [
        "#@title Anchor nodes parameters\n",
        "num_anchor_nodes = 200 #@param {type: 'number'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYgVdFfTxdfP"
      },
      "source": [
        "We now calculate the shortest paths from every anchor node to every other node using NetworkX's `single_source_shortest_path_length` function.\n",
        "\n",
        "We follow the Yang and Lu (2021) ([paper](https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf), [code](https://github.com/lustoo/OGB_link_prediction)) method of limiting the maximum shortest path length to 5.\n",
        "This cell takes around 1 minute to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9dAMvpCewGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bdb18d-dc69-4281-f52a-b10ac1fedb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest paths for node 0 to every anchor node: tensor([2., 2., 3., 3., 2., 2., 2., 3., 1., 2., 2., 2., 3., 2., 2., 2., 1., 1.,\n",
            "        2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1.,\n",
            "        2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 1., 3., 1., 2., 2.,\n",
            "        2., 3., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 3., 2.,\n",
            "        1., 3., 2., 2., 2., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2.,\n",
            "        2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2.,\n",
            "        2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2.,\n",
            "        2., 2., 2., 2., 2., 2., 3., 2., 1., 2., 1., 2., 2., 2., 2., 3., 2., 3.,\n",
            "        2., 2., 1., 1., 2., 2., 1., 3., 2., 2., 2., 2., 2., 3., 3., 2., 2., 2.,\n",
            "        2., 2., 2., 2., 2., 2., 3., 2., 1., 2., 3., 2., 1., 2., 2., 2., 1., 2.,\n",
            "        2., 2., 1., 3., 2., 2., 2., 3., 2., 3., 2., 2., 2., 1., 2., 2., 2., 2.,\n",
            "        2., 2.])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "# Sample anchor nodes\n",
        "anchor_nodes = np.random.choice(nx_ddi_graph.number_of_nodes(), size=num_anchor_nodes, replace=False)\n",
        "\n",
        "# This tensor with shape [|V|, |V_A|] will hold our computed shortest path distances\n",
        "shortest_paths_to_anchor_nodes = torch.zeros(nx_ddi_graph.number_of_nodes(), num_anchor_nodes)\n",
        "for anchor_index, anchor_node in enumerate(anchor_nodes):\n",
        "    for dst, path_length in nx.single_source_shortest_path_length(nx_ddi_graph, source=anchor_node, cutoff=5).items():\n",
        "        shortest_paths_to_anchor_nodes[dst, anchor_index] = path_length\n",
        "\n",
        "print(f'Shortest paths for node 0 to every anchor node: {shortest_paths_to_anchor_nodes[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8oUouAy1ai"
      },
      "source": [
        "Now for every edge, we add together $d_{u, v_a}$ and $d_{v, v_a}$ for every anchor node $v_a \\in V_A$, and then take the average of these summed distances. We further follow the Yang and Lu (2021) ([paper](https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf), [code](https://github.com/lustoo/OGB_link_prediction)) approach of normalizing the computed anchor distances to the range $[0, 1]$. The result is a tensor of shape $[|E|, 1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rgt-avnaX71"
      },
      "outputs": [],
      "source": [
        "# shortest_paths_to_anchor_nodes[ddi_graph.edge_index, :] creates a tensor of shape [2, |E|, |V_A|]\n",
        "# The tensor at position 0 along dimension 0 contains the anchor node distances for the source node,\n",
        "# and the tensor at position 1 contains the anchor node distances for the destination node\n",
        "edge_attr = shortest_paths_to_anchor_nodes[ddi_graph.edge_index, :].sum(dim=0).mean(dim=1, keepdim=True).to(device)\n",
        "# Normalize to range [0, 1]\n",
        "max_attr = torch.max(edge_attr)\n",
        "min_attr = torch.min(edge_attr)\n",
        "edge_attr = (edge_attr - min_attr) / (max_attr - min_attr + 1e-15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaBas81m6n_2"
      },
      "source": [
        "Now that we have our edge attributes tensor, we want to incorporate it into the GraphSAGE convolution operator to take advantage of it. Recall Equation (2) for the standard GraphSAGE layer:\n",
        "\n",
        "$$h_v^{(l + 1)} = W_1 \\cdot h_v^{(l)} + W_2 \\cdot \\text{mean}(\\{h_u^{(l)}, \\forall u \\in N(v)\\})$$\n",
        "\n",
        "Yang and Lu (2021) ([paper](https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf), [code](https://github.com/lustoo/OGB_link_prediction)) modify the message passed by each neighbor $u$ along the edge $(u, v)$ to include the edge attribute value, scaled by a learnable weight matrix and passed through a nonlinearity:\n",
        "\n",
        "$$h_v^{(l + 1)} = W_1 \\cdot h_v^{(l)} + W_2 \\cdot \\text{mean}(\\{\\text{ReLU}(h_u^{(l)} + W_3 \\cdot \\text{edge_attr}_{u, v}), \\forall u \\in N(v)\\})$$\n",
        "$$\\text{Equation } (3)$$\n",
        "\n",
        "The message function has become $m_{u \\rightarrow v}^{(l + 1)} = h_u^{(l)} + W_3 \\cdot \\text{edge_attr}_{u, v}$.\n",
        "To implement this, we need to define our own custom version of PyG's `SAGEConv`, since this doesn't have the edge attribute aspect.\n",
        "\n",
        "PyG provides `torch_geometric.nn.conv.MessagePassing` as the base class that we can extend to define our own operator. The advantage of this is that `MessagePassing` takes care of propagating messages throughout the network for us, we just have to define what the message is, and how to aggregate and update embeddings.\n",
        "\n",
        "PyG provides [full documentation and examples](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) for this process of defining custom layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spn-lfIRBRRU"
      },
      "source": [
        "Due to Colab GPU memory limits, we reduce the size of our parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxvpV6zeIBv2"
      },
      "outputs": [],
      "source": [
        "graphsage_in_channels = 128\n",
        "graphsage_hidden_channels = graphsage_in_channels\n",
        "graphsage_out_channels = graphsage_hidden_channels\n",
        "link_predictor_in_channels = graphsage_out_channels\n",
        "link_predictor_hidden_channels = link_predictor_in_channels\n",
        "edge_attr_out_channels = graphsage_hidden_channels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWHpadpjICBy"
      },
      "source": [
        "We define `SAGEConvWithEdgeAttr` to implement Equation (3). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6t11IVyhbws"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "class SAGEConvWithEdgeAttr(MessagePassing):\n",
        "    \"\"\"Custom GraphSAGE operator that includes edge attributes.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, aggr='mean',\n",
        "                comb=lambda x, y: x + y, normalize=True, **kwargs):\n",
        "        super(SAGEConvWithEdgeAttr, self).__init__(aggr=aggr)\n",
        "\n",
        "        # W_1 in Equation (3)\n",
        "        self.w_self_embedding = torch.nn.Linear(in_channels, out_channels)\n",
        "        # W_2 in Equation (3)\n",
        "        self.w_aggregation = torch.nn.Linear(in_channels, out_channels)\n",
        "        # W_3 in Equation (3)\n",
        "        self.w_edge_attr = torch.nn.Linear(1, edge_attr_out_channels)\n",
        "\n",
        "        self.comb = comb\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, size=None):\n",
        "\n",
        "        # Starts propagating messages through the network\n",
        "        # Passing edge_attr here makes it available in the message() function\n",
        "        # The second argument to propagate is x = (x_i, x_j), where x_i is features\n",
        "        # of the source nodes and x_j is features of the destination nodes (Recall\n",
        "        # that both (i, j) and (j, i) are in edge_index). We don't distinguish\n",
        "        # between source and destination nodes in this graph, so we just pass x=(x,x)\n",
        "        aggregations = self.propagate(edge_index, x=(x, x), edge_attr=edge_attr, \n",
        "                                        size=size)\n",
        "        out = self.w_self_embedding(x) + self.w_aggregation(aggregations)\n",
        "\n",
        "        if self.normalize:\n",
        "            out = F.normalize(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_attr):\n",
        "        \"\"\"Define our custom message.\"\"\"\n",
        "        # We are given x_j here because we are essentially defining what message\n",
        "        # the destination (x_j) should pass to the source (x_i). The actual passing\n",
        "        # is handled by PyG.\n",
        "        return F.relu(self.comb(x_j, self.w_edge_attr(edge_attr)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBJ7NJXiMG02"
      },
      "source": [
        "We are ready to set up a model that uses our new operator. Since we now have edge attributes, the `forward_with_edge_attr` function will be used in our `GraphSAGE` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo1Ohz0ImPEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0262e41b-27e6-42e5-980f-daba0ec01324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/data/storage.py:264: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  \" to suppress this warning\")\n"
          ]
        }
      ],
      "source": [
        "initial_node_embeddings = torch.nn.Embedding(ddi_graph.num_nodes, graphsage_in_channels).to(device)\n",
        "graphsage_model = GraphSAGE(SAGEConvWithEdgeAttr, graphsage_in_channels, \n",
        "                                 graphsage_hidden_channels,\n",
        "                                 graphsage_out_channels,\n",
        "                                 graphsage_num_layers, \n",
        "                                 dropout).to(device)\n",
        "link_predictor = LinkPredictor(link_predictor_in_channels, link_predictor_hidden_channels, dropout).to(device)                                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTXikwETMnef"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(list(initial_node_embeddings.parameters()) + list(graphsage_model.parameters()) + list(link_predictor.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhBojFvcfgUl"
      },
      "source": [
        "Run training and evaluation. The following cell takes around 15 minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAcM1PlLK34q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "0930f683-0521-4a39-f53e-845173e7b8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.3724:  10%|█         | 5/50 [01:23<13:03, 17.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5, Validation Hits@20: 0.0205, Test Hits@20: 0.0347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2990:  20%|██        | 10/50 [02:49<11:39, 17.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10, Validation Hits@20: 0.1720, Test Hits@20: 0.0971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2562:  30%|███       | 15/50 [04:14<10:13, 17.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 15, Validation Hits@20: 0.1861, Test Hits@20: 0.1103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2370:  40%|████      | 20/50 [05:40<08:46, 17.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 20, Validation Hits@20: 0.1381, Test Hits@20: 0.1236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2253:  50%|█████     | 25/50 [07:06<07:22, 17.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 25, Validation Hits@20: 0.1993, Test Hits@20: 0.1248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2116:  60%|██████    | 30/50 [08:34<05:55, 17.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 30, Validation Hits@20: 0.1949, Test Hits@20: 0.1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.2036:  70%|███████   | 35/50 [10:00<04:25, 17.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 35, Validation Hits@20: 0.1428, Test Hits@20: 0.1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1981:  80%|████████  | 40/50 [11:27<02:57, 17.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 40, Validation Hits@20: 0.2002, Test Hits@20: 0.1590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1919:  90%|█████████ | 45/50 [12:53<01:29, 17.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 45, Validation Hits@20: 0.1992, Test Hits@20: 0.1538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss 0.1891: 100%|██████████| 50/50 [14:20<00:00, 17.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 50, Validation Hits@20: 0.1918, Test Hits@20: 0.1175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epochs_bar = trange(1, epochs + 1, desc='Loss n/a')\n",
        "\n",
        "losses = []\n",
        "valid_hits_list = []\n",
        "test_hits_list = []\n",
        "for epoch in epochs_bar:\n",
        "    loss = train(graphsage_model, link_predictor, initial_node_embeddings.weight, edge_index, pos_train_edges, optimizer, batch_size, edge_attr)\n",
        "    losses.append(loss)\n",
        "\n",
        "    epochs_bar.set_description(f'Loss {loss:0.4f}')\n",
        "\n",
        "    if epoch % eval_steps == 0:\n",
        "        valid_hits, test_hits = test(graphsage_model, link_predictor, initial_node_embeddings.weight, edge_index, pos_valid_edges, neg_valid_edges, pos_test_edges, neg_test_edges, batch_size, evaluator, edge_attr)\n",
        "        print()\n",
        "        print(f'Epoch: {epoch}, Validation Hits@20: {valid_hits[\"hits@20\"]:0.4f}, Test Hits@20: {test_hits[\"hits@20\"]:0.4f}')\n",
        "        valid_hits_list.append(valid_hits['hits@20'])\n",
        "        test_hits_list.append(test_hits['hits@20'])\n",
        "    else:\n",
        "        valid_hits_list.append(valid_hits_list[-1] if valid_hits_list else 0)\n",
        "        test_hits_list.append(test_hits_list[-1] if test_hits_list else 0)\n",
        "\n",
        "plt.title(dataset.name + \": GraphSAGE with edge attributes\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.plot(losses, label=\"Training loss\")\n",
        "plt.plot(valid_hits_list, label=\"Validation Hits@20\")\n",
        "plt.plot(test_hits_list, label=\"Test Hits@20\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIvgsHb5es4E"
      },
      "source": [
        "Your results will vary. In our run, our final results are Validation Hits@20 is 0.29  and Test Hits@20 is 0.17. To be able to fit in Colab time resource restraints, we had to reduce the number of parameters in our model and train for a shorter duration while trying to learn another weight matrix, which could explain why this model didn't perform as well as the standard GraphSAGE did after 50 epochs. Nevertheless, we have successfully defined a custom GNN layer that demonstrates how we can utilize other graph properties to help with our machine learning task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opSLKCskhoRB"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Congratulations on completing the Colab! We have learned a lot:\n",
        "\n",
        "* First we learned how to load data from OGB\n",
        "* We utilized PyG's `SAGEConv` operator to build a GraphSAGE GNN and combined it with a neural network for link prediction\n",
        "* We then defined our own version of a GraphSAGE layer where we added edge attributes to the model\n",
        "\n",
        "We encourage you to explore the papers referred to in this Colab, and to take a look at other OGB datasets and graph learning tasks. There is a wide variety of problems that can be solved with Graph Neural Networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] \"Link Property Prediction.\" Open Graph Benchmark, https://ogb.stanford.edu/docs/linkprop/#ogbl-ddi\n",
        "\n",
        "[2] Hamilton, William L., et al. \"Inductive Representation Learning on Large Graphs.\" ArXiv.org, 10 Sept. 2018, https://arxiv.org/abs/1706.02216\n",
        "\n",
        "[3] Hu, Weihua, et al. \"Open Graph Benchmark: Datasets for Machine Learning on Graphs.\" ArXiv.org, 2 May 2020, https://arxiv.org/abs/2005.00687\n",
        "\n",
        "[4] Lu, Shitao, and Yang, Jing. \"Link Prediction With Structural Information.\" https://github.com/lustoo/OGB_link_prediction/blob/main/Link%20prediction%20with%20structural%20information.pdf"
      ],
      "metadata": {
        "id": "2KQGL17EQEaC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Predicting Drug-Drug Interactions using Graph Neural Networks",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}